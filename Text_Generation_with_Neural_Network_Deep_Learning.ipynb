{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "01-Text-Generation-with-Neural-Networks.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEHVq5bGqFoX",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "\n",
        "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
        "___\n",
        "# Text Generation with Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Dr02taqFob",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Reading in files as a string text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hsFxkoa_wD3u",
        "colab": {}
      },
      "source": [
        "def read_file(filepath):\n",
        "    \n",
        "    with open(filepath) as f:\n",
        "        str_text = f.read()\n",
        "    \n",
        "    return str_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "rni6tnAuqFo7",
        "colab_type": "text"
      },
      "source": [
        "### Tokenize and Clean Text using spaCy library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS8Cp4K7qFo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en',disable=['parser', 'tagger','ner'])\n",
        "\n",
        "nlp.max_length = 1198623"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxb12rAZqFpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def separate_punc(doc_text):\n",
        "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8letcKZqFpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = read_file('moby_dick_four_chapters.txt')\n",
        "tokens = separate_punc(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psOPUS-7qFpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAjptgwAqFpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45af53b4-75b5-4828-899f-6ac184190a10"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11338"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo-fYDXpqFpu",
        "colab_type": "text"
      },
      "source": [
        "## Create Sequences of Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2K_bO8XqFpv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# organize into sequences of tokens\n",
        "train_len = 25+1 # 50 training words , then one target word\n",
        "\n",
        "# Empty list of sequences\n",
        "text_sequences = []\n",
        "\n",
        "for i in range(train_len, len(tokens)):\n",
        "    \n",
        "    # Grab train_len# amount of characters\n",
        "    seq = tokens[i-train_len:i]\n",
        "    \n",
        "    # Add to list of sequences\n",
        "    text_sequences.append(seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoVhd_SeqFp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bf966817-4296-42bc-88c3-fd7aec7986b6"
      },
      "source": [
        " ' '.join(text_sequences[0])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf8z-xXaqFqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c81a43b5-5ed4-4568-9195-18994eeb0118"
      },
      "source": [
        "len(text_sequences)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcVCddLVqFqM",
        "colab_type": "text"
      },
      "source": [
        "# Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A78I1kJ9qFqO",
        "colab_type": "text"
      },
      "source": [
        "### Keras Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dih2YxoSqFqQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTclfo7vqFqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)\n",
        "sequences = tokenizer.texts_to_sequences(text_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-0IqylFqFqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "835d7497-ef04-4bf6-d48f-a96a94855f76"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 956,   14,  263,   51,  261,  408,   87,  219,  129,  111,  954,\n",
              "        260,   50,   43,   38,  315,    7,   23,  546,    3,  150,  259,\n",
              "          6, 2712,   14,   24])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg_DOTDKqFqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.index_word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmZMBvwnqFqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in sequences[0]:\n",
        "    print(f'{i} : {tokenizer.index_word[i]}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUybBkQSqFq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.word_counts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20QvRvIMqFq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = len(tokenizer.word_counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCstj9i_8RYV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8307089d-520a-4bcf-eb8b-7fcc36fca6e7"
      },
      "source": [
        "vocabulary_size"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5sIWG1vqFrB",
        "colab_type": "text"
      },
      "source": [
        "### Convert to Numpy Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDVhK72hqFrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32pnWkJXqFrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences = np.array(sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPCXL0oEqFrJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ee803e20-a1c9-45c3-8169-519c1b017e66"
      },
      "source": [
        "sequences"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 956,   14,  263, ..., 2712,   14,   24],\n",
              "       [  14,  263,   51, ...,   14,   24,  957],\n",
              "       [ 263,   51,  261, ...,   24,  957,    5],\n",
              "       ...,\n",
              "       [ 952,   12,  166, ...,  262,   53,    2],\n",
              "       [  12,  166, 2711, ...,   53,    2, 2717],\n",
              "       [ 166, 2711,    3, ...,    2, 2717,   26]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBMi-4NkqFrO",
        "colab_type": "text"
      },
      "source": [
        "# Creating an LSTM based model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW2xTlzuqFrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggkIbsSOqFr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(vocabulary_size, seq_len):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocabulary_size, 25, input_length=seq_len))\n",
        "    model.add(LSTM(150, return_sequences=True))\n",
        "    model.add(LSTM(150))\n",
        "    model.add(Dense(150, activation='relu'))\n",
        "\n",
        "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "   \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKeu9El8qFr-",
        "colab_type": "text"
      },
      "source": [
        "### Train / Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbShRGs5qFsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5iv_0lLqFsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoWRvBOSqFsQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f328a5f9-c073-4cb8-c214-b2149b82397d"
      },
      "source": [
        "# First 49 words\n",
        "sequences[:,:-1]    "
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 956,   14,  263, ...,    6, 2712,   14],\n",
              "       [  14,  263,   51, ..., 2712,   14,   24],\n",
              "       [ 263,   51,  261, ...,   14,   24,  957],\n",
              "       ...,\n",
              "       [ 952,   12,  166, ...,   11,  262,   53],\n",
              "       [  12,  166, 2711, ...,  262,   53,    2],\n",
              "       [ 166, 2711,    3, ...,   53,    2, 2717]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCp0xfZxqFsY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "907bec33-93cc-4b9e-b87c-6309c3b35a09"
      },
      "source": [
        "# last Word\n",
        "sequences[:,-1]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  24,  957,    5, ...,    2, 2717,   26])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WU1ZEKRzqFsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = sequences[:,:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPLywWY1qFs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = sequences[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPRBUUo_qFs8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = to_categorical(y, num_classes=vocabulary_size+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlP8QQmOqFtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len = X.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8FxFxsWqFtJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4dc448a4-845c-4a5b-906f-9cb713b3eaed"
      },
      "source": [
        "seq_len"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KNnh4PFqFtP",
        "colab_type": "text"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQT6cnObqFtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "dac9b47e-4743-4876-a525-36f3a8bf4fe2"
      },
      "source": [
        "# define model\n",
        "model = create_model(vocabulary_size+1, seq_len)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 25, 25)            67950     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 25, 150)           105600    \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 150)               180600    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 150)               22650     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2718)              410418    \n",
            "=================================================================\n",
            "Total params: 787,218\n",
            "Trainable params: 787,218\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PqihK7fqFtW",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2dOUhOHqFtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pickle import dump,load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7M14M9BqFte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit model \n",
        "model.fit(X, y, batch_size=128, epochs=100,verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gZpGsif2cFj",
        "colab_type": "text"
      },
      "source": [
        "**Save the model and tokenizer trained on 100 epoches**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eN7NqOTVqFtj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to file\n",
        "model.save('epoch100.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('epoch100', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7NCLg1uqFtp",
        "colab_type": "text"
      },
      "source": [
        "# Generating New Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dgn98EoqFtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXZovSncqFtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "    '''\n",
        "    INPUTS:\n",
        "    model : model that was trained on text data\n",
        "    tokenizer : tokenizer that was fit on text data\n",
        "    seq_len : length of training sequence\n",
        "    seed_text : raw string text to serve as the seed\n",
        "    num_gen_words : number of words to be generated by model\n",
        "    '''\n",
        "    \n",
        "    # Final Output\n",
        "    output_text = []\n",
        "    \n",
        "    # Intial Seed Sequence\n",
        "    input_text = seed_text\n",
        "    \n",
        "    # Create num_gen_words\n",
        "    for i in range(num_gen_words):\n",
        "        \n",
        "        # Take the input text string and encode it to a sequence\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        \n",
        "        # Pad sequences to our trained rate (50 words in the video)\n",
        "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "        \n",
        "        # Predict Class Probabilities for each word\n",
        "        pred_word_ind = model.predict_classes(pad_encoded, verbose=0)[0]\n",
        "        \n",
        "        # Grab word\n",
        "        pred_word = tokenizer.index_word[pred_word_ind] \n",
        "        \n",
        "        # Update the sequence of input text (shifting one over with the new word)\n",
        "        input_text += ' ' + pred_word\n",
        "        \n",
        "        output_text.append(pred_word)\n",
        "        \n",
        "    # Make it look like a sentence.\n",
        "    return ' '.join(output_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycpOi2YbqFt1",
        "colab_type": "text"
      },
      "source": [
        "### Grab a random seed sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EgVrdFjqFt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_sequences[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Law8MKWqFt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "random.seed(101)\n",
        "random_pick = random.randint(0,len(text_sequences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rykwN2VqFuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_seed_text = text_sequences[random_pick]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1TtzP1MqFuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_seed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQhLfMzmqFuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text = ' '.join(random_seed_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQRiUO0zqFuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6CQNwOqqFub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b8fcf66e-9534-4aee-a5eb-ffe7f6563e37"
      },
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"myself the enormous act of impaling himself in a snow hill of sporting the gloom of the ungraspable phantom of life and sun the lamp of a back and i gave myself with the door 's be order there handfuls of genteel comedies and solo forbidden is and ten stop\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnYSTZScqFug",
        "colab_type": "text"
      },
      "source": [
        "### Exploring Generated Sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AtWa_ZNqFui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_text = read_file('moby_dick_four_chapters.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO3Z_xutqFum",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e7ca7bb1-72ea-4e70-c5a1-e259470e2dc8"
      },
      "source": [
        "for i,word in enumerate(full_text.split()):\n",
        "    if word == 'inkling':\n",
        "        print(' '.join(full_text.split()[i-20:i+20]))\n",
        "        print('\\n')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "were stains of some sort or other. At first I knew not what to make of this; but soon an inkling of the truth occurred to me. I remembered a story of a white man--a whaleman too--who, falling among the\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}